{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Search engine With Tools and Agents**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Initializing the tools - Built in and Custom tools**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Built-in-tool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arxiv -- Research \n",
    "from langchain_community.tools import ArxivQueryRun ,  WikipediaQueryRun # Intract with outside world\n",
    "from langchain_community.utilities import WikipediaAPIWrapper , ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use inbuilt tool of wikipedia\n",
    "api_wrapper_wiki=WikipediaAPIWrapper(top_k_results=1 ,doc_content_chars_max=400)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper_wiki) ## Created Tool\n",
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_wrapper_arxiv=ArxivAPIWrapper(top_k_results=1  , doc_content_chars_max=400)\n",
    "arxiv=ArxivQueryRun(api_wrpper=api_wrapper_arxiv)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki , arxiv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Custom Tool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import os \n",
    "os.environ['HF_TOKEN']=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000024886C49ED0>, search_kwargs={})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "loader=WebBaseLoader(web_path=\"https://python.langchain.com/v0.2/docs/integrations/llms/\")\n",
    "docs=loader.load()\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000 , chunk_overlap=200)\n",
    "documents=text_splitter.split_documents(docs)\n",
    "vectordb=FAISS.from_documents(documents , embeddings)\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith search'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriver_tool=create_retriever_tool(retriever , \"langsmith search\" , \"Search any information about langchain\")\n",
    "retriver_tool.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\Mohit\\\\Desktop\\\\GenAI\\\\LangChain Projects\\\\Search Engine\\\\venv\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=400)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)),\n",
       " Tool(name='langsmith search', description='Search any information about langchain', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000248D3C72950>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000024886C49ED0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000248D3F9B880>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000024886C49ED0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools =[wiki , arxiv , retriver_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Run all the Tool with Agents and LLMs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tools , LLM->AgentExecuter\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "load_dotenv()\n",
    "\n",
    "## Groq api key setup\n",
    "GROQ_API_KEY=\"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\"\n",
    "os.environ['GROQ_API_KEY']=\"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\"\n",
    "\n",
    "## Model setup\n",
    "llm=ChatGroq(groq_api_key=GROQ_API_KEY , model_name=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohit\\Desktop\\GenAI\\LangChain Projects\\Search Engine\\venv\\lib\\site-packages\\langsmith\\client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "prompt=hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000248D34CC1F0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000248D34CC1F0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000248CB02EB90>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000248CB02FC10>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith search', 'description': 'Search any information about langchain', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "agent=create_openai_tools_agent(llm , tools , prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000248D34CC1F0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x00000248D34CC1F0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000248CB02EB90>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000248CB02FC10>, model_name='llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith search', 'description': 'Search any information about langchain', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\Mohit\\\\Desktop\\\\GenAI\\\\LangChain Projects\\\\Search Engine\\\\venv\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=400)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)), Tool(name='langsmith search', description='Search any information about langchain', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x00000248D3C72950>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000024886C49ED0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x00000248D3F9B880>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000024886C49ED0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executer=AgentExecutor(agent=agent , tools=tools  , verbose=True)\n",
    "agent_executer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith search` with `{'query': 'what is langsmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3myou with a guide on how to get started with Vo...Intel Weight-Only QuantizationWeight-Only Quantization for Huggingface Models with Intel Extension ...WriterWriter is a platform to generate different language content.Xorbits Inference (Xinference)Xinference is a powerful and versatile library designed to serve LLMs,YandexGPTThis notebook goes over how to use Langchain with YandexGPT.Yi01.AI, founded by Dr. Kai-Fu Lee, is a global company at the forefron...Yuan2.0Yuan2.0 is a new generation Fundamental Large Language Model develope...Edit this pageWas this page helpful?You can also leave detailed feedback on GitHub.PreviousZHIPU AINextLLMsAll LLMsCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2024 LangChain, Inc.\n",
      "\n",
      "LLMs | 🦜️🔗 LangChain\n",
      "\n",
      "FilesystemIn-memoryKey-value storesRedisUpstash RedisOtherThis is documentation for LangChain v0.2, which is no longer actively maintained.For the current stable version, see this version (Latest).ComponentsLLMsOn this pageLLMscautionYou are currently on a page documenting the use of text completion models. Many of the latest and most popular models are chat completion models.Unless you are specifically using more advanced prompting techniques, you are probably looking for this page instead.LLMs are language models that take a string as input and return a string as output.infoIf you'd like to write your own LLM, see this how-to.\n",
      "\n",
      "EngineAphrodite is the open-source large-scale inference engine designed to...ArceeThis notebook demonstrates how to use the Arcee class for generating ...Azure MLAzure ML is a platform used to build, train, and deploy machine learn...Azure OpenAIYou are currently on a page documenting the use of Azure OpenAI text ...Baichuan LLMBaichuan Inc. (https Efficiency, Health, and Happiness.Baidu QianfanBaidu AI Cloud Qianfan Platform is a one-stop large model development...BananaBanana is focused on building the machine learning infrastructure.BasetenBaseten is a Provider in the LangChain ecosystem that implements the ...BeamCalls the Beam API wrapper to deploy and make subsequent calls to an ...BedrockYou are currently on a page documenting the use of Amazon Bedrock mod...BittensorBittensor is a mining network, similar to Bitcoin, that includes buil...CerebriumAICerebrium is an AWS Sagemaker alternative. It also provides API acces...ChatGLMChatGLM-6B is an open bilingual language model\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith search` with `{'query': 'what is langsmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3myou with a guide on how to get started with Vo...Intel Weight-Only QuantizationWeight-Only Quantization for Huggingface Models with Intel Extension ...WriterWriter is a platform to generate different language content.Xorbits Inference (Xinference)Xinference is a powerful and versatile library designed to serve LLMs,YandexGPTThis notebook goes over how to use Langchain with YandexGPT.Yi01.AI, founded by Dr. Kai-Fu Lee, is a global company at the forefron...Yuan2.0Yuan2.0 is a new generation Fundamental Large Language Model develope...Edit this pageWas this page helpful?You can also leave detailed feedback on GitHub.PreviousZHIPU AINextLLMsAll LLMsCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2024 LangChain, Inc.\n",
      "\n",
      "LLMs | 🦜️🔗 LangChain\n",
      "\n",
      "FilesystemIn-memoryKey-value storesRedisUpstash RedisOtherThis is documentation for LangChain v0.2, which is no longer actively maintained.For the current stable version, see this version (Latest).ComponentsLLMsOn this pageLLMscautionYou are currently on a page documenting the use of text completion models. Many of the latest and most popular models are chat completion models.Unless you are specifically using more advanced prompting techniques, you are probably looking for this page instead.LLMs are language models that take a string as input and return a string as output.infoIf you'd like to write your own LLM, see this how-to.\n",
      "\n",
      "EngineAphrodite is the open-source large-scale inference engine designed to...ArceeThis notebook demonstrates how to use the Arcee class for generating ...Azure MLAzure ML is a platform used to build, train, and deploy machine learn...Azure OpenAIYou are currently on a page documenting the use of Azure OpenAI text ...Baichuan LLMBaichuan Inc. (https Efficiency, Health, and Happiness.Baidu QianfanBaidu AI Cloud Qianfan Platform is a one-stop large model development...BananaBanana is focused on building the machine learning infrastructure.BasetenBaseten is a Provider in the LangChain ecosystem that implements the ...BeamCalls the Beam API wrapper to deploy and make subsequent calls to an ...BedrockYou are currently on a page documenting the use of Amazon Bedrock mod...BittensorBittensor is a mining network, similar to Bitcoin, that includes buil...CerebriumAICerebrium is an AWS Sagemaker alternative. It also provides API acces...ChatGLMChatGLM-6B is an open bilingual language model\u001b[0m\u001b[32;1m\u001b[1;3mIt seems like you're looking for more information about Langsmith. Langsmith is a platform that provides a variety of tools and resources for building and training large language models. It appears to be a comprehensive platform that covers various aspects of natural language processing, including model development, deployment, and inference.\n",
      "\n",
      "Some of the notable features and components of Langsmith include:\n",
      "\n",
      "1. LLMs (Large Language Models): Langsmith provides a range of pre-trained LLMs that can be used for various NLP tasks, such as text completion, question answering, and language translation.\n",
      "2. Engine: Aphrodite is an open-source large-scale inference engine designed to serve LLMs.\n",
      "3. Providers: Langsmith has a range of providers, including Baseten, Beam, and Bedrock, that implement the LangChain ecosystem.\n",
      "4. Mining Network: Bittensor is a mining network, similar to Bitcoin, that includes building, training, and deploying LLMs.\n",
      "5. API Access: Langsmith provides API access to its models and platforms, making it easier to integrate them into various applications.\n",
      "\n",
      "Langsmith also appears to have a strong focus on innovation and community engagement, with initiatives like the LangChain GitHub organization and a community blog.\n",
      "\n",
      "Overall, Langsmith seems like a powerful and versatile platform for anyone interested in building and working with large language models.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about langsmith',\n",
       " 'output': \"It seems like you're looking for more information about Langsmith. Langsmith is a platform that provides a variety of tools and resources for building and training large language models. It appears to be a comprehensive platform that covers various aspects of natural language processing, including model development, deployment, and inference.\\n\\nSome of the notable features and components of Langsmith include:\\n\\n1. LLMs (Large Language Models): Langsmith provides a range of pre-trained LLMs that can be used for various NLP tasks, such as text completion, question answering, and language translation.\\n2. Engine: Aphrodite is an open-source large-scale inference engine designed to serve LLMs.\\n3. Providers: Langsmith has a range of providers, including Baseten, Beam, and Bedrock, that implement the LangChain ecosystem.\\n4. Mining Network: Bittensor is a mining network, similar to Bitcoin, that includes building, training, and deploying LLMs.\\n5. API Access: Langsmith provides API access to its models and platforms, making it easier to integrate them into various applications.\\n\\nLangsmith also appears to have a strong focus on innovation and community engagement, with initiatives like the LangChain GitHub organization and a community blog.\\n\\nOverall, Langsmith seems like a powerful and versatile platform for anyone interested in building and working with large language models.\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({'input' : 'Tell me about langsmith'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Machine learning'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions. Advances in the field of deep learning have allowed neural networks to surpass many previous approaches in performance.\n",
      "ML\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Artificial intelligence'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Artificial intelligence\n",
      "Summary: Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving def\u001b[0m\u001b[32;1m\u001b[1;3mBased on the provided information, I can provide a response that combines the information from the two tool calls.\n",
      "\n",
      "Machine learning is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.\n",
      "\n",
      "Artificial intelligence, in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving desired outcomes.\n",
      "\n",
      "In other words, machine learning is a subset of artificial intelligence that focuses on developing algorithms that can learn from data and improve their performance over time.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is machine learning',\n",
       " 'output': 'Based on the provided information, I can provide a response that combines the information from the two tool calls.\\n\\nMachine learning is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.\\n\\nArtificial intelligence, in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving desired outcomes.\\n\\nIn other words, machine learning is a subset of artificial intelligence that focuses on developing algorithms that can learn from data and improve their performance over time.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({'input' : 'What is machine learning'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Attention Is All You Need'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Attention Is All You Need\n",
      "Summary: \"Attention Is All You Need\" is a 2017 landmark research paper in machine learning authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al. It is considered a foundational paper in modern artificial intelligence, as the \u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith search` with `{'query': 'transformer deep learning architecture'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mis a mining network, similar to Bitcoin, that includes buil...CerebriumAICerebrium is an AWS Sagemaker alternative. It also provides API acces...ChatGLMChatGLM-6B is an open bilingual language model based on General Langu...ClarifaiClarifai is an AI Platform that provides the full AI lifecycle rangin...Cloudflare Workers AICloudflare AI documentation listed all generative text models availab...CohereYou are currently on a page documenting the use of Cohere models as t...C TransformersThe C Transformers library provides Python bindings for GGML models.CTranslate2CTranslate2 is a C++ and Python library for efficient inference with ...DatabricksDatabricks Lakehouse Platform unifies data, analytics, and AI on one ...DeepInfraDeepInfra is a serverless inference as a service that provides access...DeepSparseThis page covers how to use the DeepSparse inference runtime within L...Eden AIEden AI is revolutionizing the AI landscape by uniting the best AI pr...ExLlamaV2ExLlamav2 is a fast\n",
      "\n",
      "access...DeepSparseThis page covers how to use the DeepSparse inference runtime within L...Eden AIEden AI is revolutionizing the AI landscape by uniting the best AI pr...ExLlamaV2ExLlamav2 is a fast inference library for running LLMs locally on mod...FireworksYou are currently on a page documenting the use of Fireworks models a...ForefrontAIThe Forefront platform gives you the ability to fine-tune and use ope...FriendliFriendli enhances AI application performance and optimizes cost savin...GigaChatThis notebook shows how to use LangChain with GigaChat.Google AIYou are currently on a page documenting the use of Google models as t...Google Cloud Vertex AIYou are currently on a page documenting the use of Google Vertex text...GooseAIGooseAI is a fully managed NLP-as-a-Service, delivered via API. Goose...GPT4AllGitHub:nomic-ai/gpt4all an ecosystem of open-source chatbots trained ...GradientGradient allows to fine tune and get completions on LLMs with a simpl...Huggingface EndpointsThe\n",
      "\n",
      "open-source toolkit for optimizing and deploying AI i...PetalsPetals runs 100B+ language models at home, BitTorrent-style.PipelineAIPipelineAI allows you to run your ML models at scale in the cloud. It...PredibasePredibase allows you to train, fine-tune, and deploy any ML model—fro...Prediction GuardBasic LLM usagePromptLayer OpenAIPromptLayer is the first platform that allows you to track, manage, a...RELLMRELLM is a library that wraps local Hugging Face pipeline models for ...ReplicateReplicate runs machine learning models in the cloud. We have a librar...RunhouseRunhouse allows remote compute and data across environments and users...SageMakerEndpointAmazon SageMaker is a system that can build, train, and deploy machin...SambaNovaSambaNova's Sambaverse and Sambastudio are platforms for running your...SolarThis community integration is deprecated. You should use ChatUpstage ...SparkLLMSparkLLM is a large-scale cognitive model independently developed by ...StochasticAIStochastic\n",
      "\n",
      "EmbeddingsFastEmbed by QdrantFireworksGigaChatGoogle Generative AI EmbeddingsGoogle Vertex AIGPT4AllGradientHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceLocal BGE Embeddings with IPEX-LLM on Intel CPULocal BGE Embeddings with IPEX-LLM on Intel GPUIntel® Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAIModelScopeMosaicMLNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPremAISageMakerSambaNovaSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIDocument\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Transformer deep learning architecture'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Transformer (deep learning architecture)\n",
      "Summary: A transformer is a deep learning architecture developed by researchers at Google and based on the multi-head attention mechanism, proposed in the 2017 paper \"Attention Is All You Need\". Text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer,\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'Attention mechanisms in deep learning'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2022-03-27\n",
      "Title: A General Survey on Attention Mechanisms in Deep Learning\n",
      "Authors: Gianni Brauwers, Flavius Frasincar\n",
      "Summary: Attention is an important mechanism that can be employed for a variety of\n",
      "deep learning models across many different domains and tasks. This survey\n",
      "provides an overview of the most important attention mechanisms proposed in the\n",
      "literature. The various attention mechanisms are explained by means of a\n",
      "framework consisting of a general attention model, uniform notation, and a\n",
      "comprehensive taxonomy of attention mechanisms. Furthermore, the various\n",
      "measures for evaluating attention models are reviewed, and methods to\n",
      "characterize the structure of attention models based on the proposed framework\n",
      "are discussed. Last, future work in the field of attention models is\n",
      "considered.\n",
      "\n",
      "Published: 2022-07-04\n",
      "Title: Attention mechanisms for physiological signal deep learning: which attention should we take?\n",
      "Authors: Seong-A Park, Hyung-Chul Lee, Chul-Woo Jung, Hyun-Lim Yang\n",
      "Summary: Attention mechanisms are widely used to dramatically improve deep learning\n",
      "model performance in various fields. However, their general ability to improve\n",
      "the performance of physiological signal deep learning model is immature. In\n",
      "this study, we experimentally analyze four attention mechanisms (e.g.,\n",
      "squeeze-and-excitation, non-local, convolutional block attention module, and\n",
      "multi-head self-attention) and three convolutional neural network (CNN)\n",
      "architectures (e.g., VGG, ResNet, and Inception) for two representative\n",
      "physiological signal prediction tasks: the classification for predicting\n",
      "hypotension and the regression for predicting cardiac output (CO). We evaluated\n",
      "multiple combinations for performance and convergence of physiological signal\n",
      "deep learning model. Accordingly, the CNN models with the spatial attention\n",
      "mechanism showed the best performance in the classification problem, whereas\n",
      "the channel attention mechanism achieved the lowest error in the regression\n",
      "problem. Moreover, the performance and convergence of the CNN models with\n",
      "attention mechanisms were better than stand-alone self-attention models in both\n",
      "problems. Hence, we verified that convolutional operation and attention\n",
      "mechanisms are complementary and provide faster convergence time, despite the\n",
      "stand-alone self-attention models requiring fewer parameters.\n",
      "\n",
      "Published: 2021-11-29\n",
      "Title: Neural Attention for Image Captioning: Review of Outstanding Methods\n",
      "Authors: Zanyar Zohourianshahzadi, Jugal K. Kalita\n",
      "Summary: Image captioning is the task of automatically generating sentences that\n",
      "describe an input image in the best way possible. The most successful\n",
      "techniques for automatically generating image captions have recently used\n",
      "attentive deep learning models. There are variations in the way deep learning\n",
      "models with attention are designed. In this survey, we provide a review of\n",
      "literature related to attentive deep learning models for image captioning.\n",
      "Instead of offering a comprehensive review of all prior work on deep image\n",
      "captioning models, we explain various types of attention mechanisms used for\n",
      "the task of image captioning in deep learning models. The most successful deep\n",
      "learning models used for image captioning follow the encoder-decoder\n",
      "architecture, although there are differences in the way these models employ\n",
      "attention mechanisms. Via analysis on performance results from different\n",
      "attentive deep models for image captioning, we aim at finding the most\n",
      "successful types of attention mechanisms in deep models for image captioning.\n",
      "Soft attention, bottom-up attention, and multi-head attention are the types of\n",
      "attention mechanism widely used in state-of-the-art attentive deep learning\n",
      "models for image captioning. At the current time, the best results are achieved\n",
      "from variants of multi-head attention with bottom-up attention.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith search` with `{'query': 'Attention mechanisms in deep learning applications'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3maccess...DeepSparseThis page covers how to use the DeepSparse inference runtime within L...Eden AIEden AI is revolutionizing the AI landscape by uniting the best AI pr...ExLlamaV2ExLlamav2 is a fast inference library for running LLMs locally on mod...FireworksYou are currently on a page documenting the use of Fireworks models a...ForefrontAIThe Forefront platform gives you the ability to fine-tune and use ope...FriendliFriendli enhances AI application performance and optimizes cost savin...GigaChatThis notebook shows how to use LangChain with GigaChat.Google AIYou are currently on a page documenting the use of Google models as t...Google Cloud Vertex AIYou are currently on a page documenting the use of Google Vertex text...GooseAIGooseAI is a fully managed NLP-as-a-Service, delivered via API. Goose...GPT4AllGitHub:nomic-ai/gpt4all an ecosystem of open-source chatbots trained ...GradientGradient allows to fine tune and get completions on LLMs with a simpl...Huggingface EndpointsThe\n",
      "\n",
      "EmbeddingsFastEmbed by QdrantFireworksGigaChatGoogle Generative AI EmbeddingsGoogle Vertex AIGPT4AllGradientHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceLocal BGE Embeddings with IPEX-LLM on Intel CPULocal BGE Embeddings with IPEX-LLM on Intel GPUIntel® Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAIModelScopeMosaicMLNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPremAISageMakerSambaNovaSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIDocument\n",
      "\n",
      "APIKonkoLayerup SecurityLlama.cppLlamafileLM Format EnforcerManifestMinimaxMLX Local PipelinesModalMoonshotChatMosaicMLNLP Cloudoci_generative_aiOCI Data Science Model Deployment EndpointOctoAIOllamaOpaquePromptsOpenAIOpenLLMOpenLMOpenVINOPetalsPipelineAIPredibasePrediction GuardPromptLayer OpenAIRELLMReplicateRunhouseSageMakerEndpointSambaNovaSolarSparkLLMStochasticAINebula (Symbl.ai)TextGenTitan TakeoffTogether AITongyi QwenvLLMVolc Engine MaasIntel Weight-Only QuantizationWriterXorbits Inference (Xinference)YandexGPTYiYuan2.0Embedding modelsEmbedding modelsAI21Aleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGigaChatGoogle Generative AI EmbeddingsGoogle Vertex AIGPT4AllGradientHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceLocal BGE Embeddings\n",
      "\n",
      "is a mining network, similar to Bitcoin, that includes buil...CerebriumAICerebrium is an AWS Sagemaker alternative. It also provides API acces...ChatGLMChatGLM-6B is an open bilingual language model based on General Langu...ClarifaiClarifai is an AI Platform that provides the full AI lifecycle rangin...Cloudflare Workers AICloudflare AI documentation listed all generative text models availab...CohereYou are currently on a page documenting the use of Cohere models as t...C TransformersThe C Transformers library provides Python bindings for GGML models.CTranslate2CTranslate2 is a C++ and Python library for efficient inference with ...DatabricksDatabricks Lakehouse Platform unifies data, analytics, and AI on one ...DeepInfraDeepInfra is a serverless inference as a service that provides access...DeepSparseThis page covers how to use the DeepSparse inference runtime within L...Eden AIEden AI is revolutionizing the AI landscape by uniting the best AI pr...ExLlamaV2ExLlamav2 is a fast\u001b[0m\u001b[32;1m\u001b[1;3mIt seems like the tool call yielded a large amount of text, but it appears to be a list of various AI models, platforms, and services. To provide a more structured response, I would like to clarify the context and purpose of the original tool call.\n",
      "\n",
      "Could you please provide more information on what you were trying to achieve with the original tool call, and what kind of response you were expecting? This will help me better understand your needs and provide a more accurate and relevant response.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is attention is all you need paper',\n",
       " 'output': 'It seems like the tool call yielded a large amount of text, but it appears to be a list of various AI models, platforms, and services. To provide a more structured response, I would like to clarify the context and purpose of the original tool call.\\n\\nCould you please provide more information on what you were trying to achieve with the original tool call, and what kind of response you were expecting? This will help me better understand your needs and provide a more accurate and relevant response.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({'input': 'what is attention is all you need paper'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
