{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langsmith langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb8fHLa6gmhP",
        "outputId": "f93b9b5b-512c-4319-cb6b-b3e9dece2920"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Requirement already satisfied: langsmith in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.61-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith) (1.0.0)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.9-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.48-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.2.2)\n",
            "Downloading langgraph-0.2.61-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.9-py3-none-any.whl (37 kB)\n",
            "Downloading langgraph_sdk-0.1.48-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langgraph-sdk, langgraph-checkpoint, langgraph\n",
            "Successfully installed langgraph-0.2.61 langgraph-checkpoint-2.0.9 langgraph-sdk-0.1.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain_groq langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AxJqPhPg6Z5",
        "outputId": "b80b82cd-3c07-4fd8-d695-fbae47fa5694"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.29)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain_groq) (0.13.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.7.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "groq_api_key=userdata.get('Groq_API_Key')\n",
        "langchain_api_key=userdata.get('LangChain_API_Key')\n",
        "os.environ['LANGCHAIN_API_KEY'] = userdata.get('LangChain_API_Key')\n",
        "os.environ['GROQ_API_KEY']=userdata.get('Groq_API_Key')\n",
        "os.environ['LANGCHAIN_TRACING_V2']='true'\n",
        "os.environ['LANGCHAIN_PROJECT']='CourseLanggraph'"
      ],
      "metadata": {
        "id": "nmQWNX_Bi7kc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "HZ4lgozNjtBJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatGroq(groq_api_key=groq_api_key , model_name=\"gemma2-9b-it\")"
      ],
      "metadata": {
        "id": "frUMQFNzzh1D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYpFOeWo0Csb",
        "outputId": "a3e7e05c-0be4-4f91-f8c9-203f00bf0fbf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x78f6411131f0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x78f641111600>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Start Building Chabot using LangGraph**"
      ],
      "metadata": {
        "id": "1o-STGhf1XCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph , START , END\n",
        "from langgraph.graph.message import add_messages"
      ],
      "metadata": {
        "id": "oYQzY4Rx0IYU"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    messages:Annotated[list,add_messages]\n",
        "\n",
        "graph_builder=StateGraph(State)\n"
      ],
      "metadata": {
        "id": "-c1KNH6y14lW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-D_reT4R39me",
        "outputId": "ea9b73da-80a3-403d-f335-95f9ba9d35a7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78f631003bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(state:State):\n",
        "  return {\"messages\":llm.invoke(state['messages'])}\n"
      ],
      "metadata": {
        "id": "yjZPRFYl3-6r"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_node(\"chatbot\" , chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1rSRSIq7Odi",
        "outputId": "5ac0015a-cde8-463a-b854-a98225f2acb7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78f631003bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder.add_edge(START , \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\" , END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usjmtWoU7UNl",
        "outputId": "e9279d5b-2364-4e29-d8ce-47f0725176f4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78f631003bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph=graph_builder.compile()"
      ],
      "metadata": {
        "id": "SMO7KKM09yvh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image , display\n",
        "\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "-0ZaVyBd-NwY",
        "outputId": "b253e2f6-cdeb-4f79-ae98-cc6b479c4038"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_input=input(\"User :\")\n",
        "  if user_input.lower() in [\"quite\" , \"q\"]:\n",
        "    print(\"Good Bye\")\n",
        "    break\n",
        "  for event in graph.stream({'messages':('user' , user_input)}):\n",
        "    print(event.values())\n",
        "    for value in event.values():\n",
        "      print(value['messages'])\n",
        "      print(\"Assistant :\" , value[\"messages\"].content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4Potwlx-qo4",
        "outputId": "33674bb2-e4fb-439c-e4de-b58b2e6005b0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User :hello\n",
            "dict_values([{'messages': AIMessage(content='Hello! ðŸ‘‹  How can I help you today? ðŸ˜„\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 10, 'total_tokens': 25, 'completion_time': 0.027272727, 'prompt_time': 4.1e-07, 'queue_time': 0.021464788000000002, 'total_time': 0.027273137}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-00fb0314-fb14-4df4-aadc-083ea48876eb-0', usage_metadata={'input_tokens': 10, 'output_tokens': 15, 'total_tokens': 25})}])\n",
            "content='Hello! ðŸ‘‹  How can I help you today? ðŸ˜„\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 10, 'total_tokens': 25, 'completion_time': 0.027272727, 'prompt_time': 4.1e-07, 'queue_time': 0.021464788000000002, 'total_time': 0.027273137}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-00fb0314-fb14-4df4-aadc-083ea48876eb-0' usage_metadata={'input_tokens': 10, 'output_tokens': 15, 'total_tokens': 25}\n",
            "Assistant : Hello! ðŸ‘‹  How can I help you today? ðŸ˜„\n",
            "\n",
            "User :who are you?\n",
            "dict_values([{'messages': AIMessage(content=\"I am Gemma, an open-weights AI assistant. I am a large language model trained by Google DeepMind.\\n\\nHere are some key things to know about me:\\n\\n* **Open-Weights:** My weights are publicly accessible. This means anyone can see and use the underlying code that makes me work.\\n* **Text-Only:** I can only understand and generate text. I can't process images, audio, or video.\\n* **Limited Knowledge:** I don't have access to real-time information or Google Search. My knowledge is based on the data I was trained on, which has a cutoff point.\\n\\nI'm here to help with a variety of tasks, such as:\\n\\n* **Generating creative content:**\\n\\nI can write stories, poems, articles, and more.\\n* **Answering questions:** I can provide information on a wide range of topics, based on my training data.\\n* **Summarizing text:** I can condense large amounts of text into shorter, more manageable summaries.\\n* **Translating languages:** I can translate text between different languages.\\n\\nKeep in mind that I am still under development and learning. I may not always be perfect, but I am always working to improve.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 255, 'prompt_tokens': 13, 'total_tokens': 268, 'completion_time': 0.463636364, 'prompt_time': 6.995e-05, 'queue_time': 0.01990325, 'total_time': 0.463706314}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-de698ef9-ee3b-4b7f-bc4d-4235ab760f95-0', usage_metadata={'input_tokens': 13, 'output_tokens': 255, 'total_tokens': 268})}])\n",
            "content=\"I am Gemma, an open-weights AI assistant. I am a large language model trained by Google DeepMind.\\n\\nHere are some key things to know about me:\\n\\n* **Open-Weights:** My weights are publicly accessible. This means anyone can see and use the underlying code that makes me work.\\n* **Text-Only:** I can only understand and generate text. I can't process images, audio, or video.\\n* **Limited Knowledge:** I don't have access to real-time information or Google Search. My knowledge is based on the data I was trained on, which has a cutoff point.\\n\\nI'm here to help with a variety of tasks, such as:\\n\\n* **Generating creative content:**\\n\\nI can write stories, poems, articles, and more.\\n* **Answering questions:** I can provide information on a wide range of topics, based on my training data.\\n* **Summarizing text:** I can condense large amounts of text into shorter, more manageable summaries.\\n* **Translating languages:** I can translate text between different languages.\\n\\nKeep in mind that I am still under development and learning. I may not always be perfect, but I am always working to improve.\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 255, 'prompt_tokens': 13, 'total_tokens': 268, 'completion_time': 0.463636364, 'prompt_time': 6.995e-05, 'queue_time': 0.01990325, 'total_time': 0.463706314}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-de698ef9-ee3b-4b7f-bc4d-4235ab760f95-0' usage_metadata={'input_tokens': 13, 'output_tokens': 255, 'total_tokens': 268}\n",
            "Assistant : I am Gemma, an open-weights AI assistant. I am a large language model trained by Google DeepMind.\n",
            "\n",
            "Here are some key things to know about me:\n",
            "\n",
            "* **Open-Weights:** My weights are publicly accessible. This means anyone can see and use the underlying code that makes me work.\n",
            "* **Text-Only:** I can only understand and generate text. I can't process images, audio, or video.\n",
            "* **Limited Knowledge:** I don't have access to real-time information or Google Search. My knowledge is based on the data I was trained on, which has a cutoff point.\n",
            "\n",
            "I'm here to help with a variety of tasks, such as:\n",
            "\n",
            "* **Generating creative content:**\n",
            "\n",
            "I can write stories, poems, articles, and more.\n",
            "* **Answering questions:** I can provide information on a wide range of topics, based on my training data.\n",
            "* **Summarizing text:** I can condense large amounts of text into shorter, more manageable summaries.\n",
            "* **Translating languages:** I can translate text between different languages.\n",
            "\n",
            "Keep in mind that I am still under development and learning. I may not always be perfect, but I am always working to improve.\n",
            "\n",
            "User :what is GenAI\n",
            "dict_values([{'messages': AIMessage(content=\"GenAI stands for **Generative Artificial Intelligence**. \\n\\nIt's a type of AI that focuses on creating new content, rather than just analyzing existing data. Think of it like this:\\n\\n* **Traditional AI:**  Analyzes data to find patterns and make predictions (e.g., recommending products you might like).\\n* **GenAI:**  Uses learned patterns to generate new content (e.g., writing a poem, composing music, designing a logo).\\n\\n**Here are some key things to know about GenAI:**\\n\\n* **Training Data:** GenAI models are trained on massive datasets of text, code, images, audio, or other types of data. This allows them to learn the underlying patterns and structures of that data.\\n* **Generative Capabilities:** Once trained, GenAI models can generate new content that resembles the style and characteristics of the data they were trained on.\\n* **Applications:** GenAI has a wide range of applications, including:\\n    * **Text Generation:** Writing stories, articles, poems, dialogue, and more.\\n    * **Image Generation:** Creating realistic or artistic images from text descriptions.\\n    * **Code Generation:** Writing computer code in different programming languages.\\n    * **Music Composition:** Generating original musical pieces in various styles.\\n    * **Video Generation:** Creating short videos or animations.\\n\\n* **Examples of GenAI models:**\\n\\n    * **GPT-3 (text generation)**\\n    * **DALL-E 2 (image generation)**\\n    * **Stable Diffusion (image generation)**\\n    * **Jukebox (music generation)**\\n\\n**It's important to note that GenAI is still a rapidly evolving field, and there are ongoing discussions about its ethical implications, potential biases, and responsible use.**\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 369, 'prompt_tokens': 13, 'total_tokens': 382, 'completion_time': 0.670909091, 'prompt_time': 7.6939e-05, 'queue_time': 0.021531948, 'total_time': 0.67098603}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-3a398e3c-b105-45ac-b7ea-be0c3f710a36-0', usage_metadata={'input_tokens': 13, 'output_tokens': 369, 'total_tokens': 382})}])\n",
            "content=\"GenAI stands for **Generative Artificial Intelligence**. \\n\\nIt's a type of AI that focuses on creating new content, rather than just analyzing existing data. Think of it like this:\\n\\n* **Traditional AI:**  Analyzes data to find patterns and make predictions (e.g., recommending products you might like).\\n* **GenAI:**  Uses learned patterns to generate new content (e.g., writing a poem, composing music, designing a logo).\\n\\n**Here are some key things to know about GenAI:**\\n\\n* **Training Data:** GenAI models are trained on massive datasets of text, code, images, audio, or other types of data. This allows them to learn the underlying patterns and structures of that data.\\n* **Generative Capabilities:** Once trained, GenAI models can generate new content that resembles the style and characteristics of the data they were trained on.\\n* **Applications:** GenAI has a wide range of applications, including:\\n    * **Text Generation:** Writing stories, articles, poems, dialogue, and more.\\n    * **Image Generation:** Creating realistic or artistic images from text descriptions.\\n    * **Code Generation:** Writing computer code in different programming languages.\\n    * **Music Composition:** Generating original musical pieces in various styles.\\n    * **Video Generation:** Creating short videos or animations.\\n\\n* **Examples of GenAI models:**\\n\\n    * **GPT-3 (text generation)**\\n    * **DALL-E 2 (image generation)**\\n    * **Stable Diffusion (image generation)**\\n    * **Jukebox (music generation)**\\n\\n**It's important to note that GenAI is still a rapidly evolving field, and there are ongoing discussions about its ethical implications, potential biases, and responsible use.**\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 369, 'prompt_tokens': 13, 'total_tokens': 382, 'completion_time': 0.670909091, 'prompt_time': 7.6939e-05, 'queue_time': 0.021531948, 'total_time': 0.67098603}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-3a398e3c-b105-45ac-b7ea-be0c3f710a36-0' usage_metadata={'input_tokens': 13, 'output_tokens': 369, 'total_tokens': 382}\n",
            "Assistant : GenAI stands for **Generative Artificial Intelligence**. \n",
            "\n",
            "It's a type of AI that focuses on creating new content, rather than just analyzing existing data. Think of it like this:\n",
            "\n",
            "* **Traditional AI:**  Analyzes data to find patterns and make predictions (e.g., recommending products you might like).\n",
            "* **GenAI:**  Uses learned patterns to generate new content (e.g., writing a poem, composing music, designing a logo).\n",
            "\n",
            "**Here are some key things to know about GenAI:**\n",
            "\n",
            "* **Training Data:** GenAI models are trained on massive datasets of text, code, images, audio, or other types of data. This allows them to learn the underlying patterns and structures of that data.\n",
            "* **Generative Capabilities:** Once trained, GenAI models can generate new content that resembles the style and characteristics of the data they were trained on.\n",
            "* **Applications:** GenAI has a wide range of applications, including:\n",
            "    * **Text Generation:** Writing stories, articles, poems, dialogue, and more.\n",
            "    * **Image Generation:** Creating realistic or artistic images from text descriptions.\n",
            "    * **Code Generation:** Writing computer code in different programming languages.\n",
            "    * **Music Composition:** Generating original musical pieces in various styles.\n",
            "    * **Video Generation:** Creating short videos or animations.\n",
            "\n",
            "* **Examples of GenAI models:**\n",
            "\n",
            "    * **GPT-3 (text generation)**\n",
            "    * **DALL-E 2 (image generation)**\n",
            "    * **Stable Diffusion (image generation)**\n",
            "    * **Jukebox (music generation)**\n",
            "\n",
            "**It's important to note that GenAI is still a rapidly evolving field, and there are ongoing discussions about its ethical implications, potential biases, and responsible use.**\n",
            "\n",
            "User :who won the cricket world cup in 2011\n",
            "dict_values([{'messages': AIMessage(content='**India** won the Cricket World Cup in 2011.  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 21, 'total_tokens': 40, 'completion_time': 0.034545455, 'prompt_time': 0.0001328, 'queue_time': 0.020787558, 'total_time': 0.034678255}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-913fde89-973c-417c-af0f-9c9f388456ae-0', usage_metadata={'input_tokens': 21, 'output_tokens': 19, 'total_tokens': 40})}])\n",
            "content='**India** won the Cricket World Cup in 2011.  \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 21, 'total_tokens': 40, 'completion_time': 0.034545455, 'prompt_time': 0.0001328, 'queue_time': 0.020787558, 'total_time': 0.034678255}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-913fde89-973c-417c-af0f-9c9f388456ae-0' usage_metadata={'input_tokens': 21, 'output_tokens': 19, 'total_tokens': 40}\n",
            "Assistant : **India** won the Cricket World Cup in 2011.  \n",
            "\n",
            "User :who was the captain \n",
            "dict_values([{'messages': AIMessage(content='Please provide me with more context! \\n\\nWho is the \"captain\" of?  \\n\\nFor example, you could ask:\\n\\n* Who was the captain of the Titanic?\\n* Who was the captain of the US women\\'s soccer team in the 2019 World Cup?\\n* Who is the captain of the Starship Enterprise in the original series? \\n\\n\\nOnce you tell me what you\\'re interested in, I can give you the answer! \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 99, 'prompt_tokens': 14, 'total_tokens': 113, 'completion_time': 0.18, 'prompt_time': 7.4649e-05, 'queue_time': 0.020312841, 'total_time': 0.180074649}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-7fc4a2d6-3b7f-4e95-bc38-d5752deba063-0', usage_metadata={'input_tokens': 14, 'output_tokens': 99, 'total_tokens': 113})}])\n",
            "content='Please provide me with more context! \\n\\nWho is the \"captain\" of?  \\n\\nFor example, you could ask:\\n\\n* Who was the captain of the Titanic?\\n* Who was the captain of the US women\\'s soccer team in the 2019 World Cup?\\n* Who is the captain of the Starship Enterprise in the original series? \\n\\n\\nOnce you tell me what you\\'re interested in, I can give you the answer! \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 99, 'prompt_tokens': 14, 'total_tokens': 113, 'completion_time': 0.18, 'prompt_time': 7.4649e-05, 'queue_time': 0.020312841, 'total_time': 0.180074649}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-7fc4a2d6-3b7f-4e95-bc38-d5752deba063-0' usage_metadata={'input_tokens': 14, 'output_tokens': 99, 'total_tokens': 113}\n",
            "Assistant : Please provide me with more context! \n",
            "\n",
            "Who is the \"captain\" of?  \n",
            "\n",
            "For example, you could ask:\n",
            "\n",
            "* Who was the captain of the Titanic?\n",
            "* Who was the captain of the US women's soccer team in the 2019 World Cup?\n",
            "* Who is the captain of the Starship Enterprise in the original series? \n",
            "\n",
            "\n",
            "Once you tell me what you're interested in, I can give you the answer! \n",
            "\n",
            "User :who was the captain of indian team at that time\n",
            "dict_values([{'messages': AIMessage(content=\"Please provide me with the context! \\n\\nTo tell you who the captain of the Indian team was, I need to know:\\n\\n* **What sport are you referring to?** (Cricket, football, hockey, etc.)\\n* **What time period are you interested in?** (A specific year, tournament, or era)\\n\\n\\nLet me know, and I'll be happy to help! \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 19, 'total_tokens': 105, 'completion_time': 0.156363636, 'prompt_time': 7.489e-05, 'queue_time': 0.018985857999999998, 'total_time': 0.156438526}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d563ad53-bfa5-4f77-ac63-67d3ad9f25f0-0', usage_metadata={'input_tokens': 19, 'output_tokens': 86, 'total_tokens': 105})}])\n",
            "content=\"Please provide me with the context! \\n\\nTo tell you who the captain of the Indian team was, I need to know:\\n\\n* **What sport are you referring to?** (Cricket, football, hockey, etc.)\\n* **What time period are you interested in?** (A specific year, tournament, or era)\\n\\n\\nLet me know, and I'll be happy to help! \\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 19, 'total_tokens': 105, 'completion_time': 0.156363636, 'prompt_time': 7.489e-05, 'queue_time': 0.018985857999999998, 'total_time': 0.156438526}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-d563ad53-bfa5-4f77-ac63-67d3ad9f25f0-0' usage_metadata={'input_tokens': 19, 'output_tokens': 86, 'total_tokens': 105}\n",
            "Assistant : Please provide me with the context! \n",
            "\n",
            "To tell you who the captain of the Indian team was, I need to know:\n",
            "\n",
            "* **What sport are you referring to?** (Cricket, football, hockey, etc.)\n",
            "* **What time period are you interested in?** (A specific year, tournament, or era)\n",
            "\n",
            "\n",
            "Let me know, and I'll be happy to help! \n",
            "\n",
            "User :who was the captain of indian team when india won teh cricket world cup in 2011\n",
            "dict_values([{'messages': AIMessage(content='The captain of the Indian team when India won the Cricket World Cup in 2011 was **MS Dhoni**. \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 29, 'total_tokens': 57, 'completion_time': 0.050909091, 'prompt_time': 0.000133509, 'queue_time': 0.019289469, 'total_time': 0.0510426}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-30925e2a-862f-4e79-869b-e8855e4c56e9-0', usage_metadata={'input_tokens': 29, 'output_tokens': 28, 'total_tokens': 57})}])\n",
            "content='The captain of the Indian team when India won the Cricket World Cup in 2011 was **MS Dhoni**. \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 29, 'total_tokens': 57, 'completion_time': 0.050909091, 'prompt_time': 0.000133509, 'queue_time': 0.019289469, 'total_time': 0.0510426}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run-30925e2a-862f-4e79-869b-e8855e4c56e9-0' usage_metadata={'input_tokens': 29, 'output_tokens': 28, 'total_tokens': 57}\n",
            "Assistant : The captain of the Indian team when India won the Cricket World Cup in 2011 was **MS Dhoni**. \n",
            "\n",
            "User :q\n",
            "Good Bye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YxNa1oTbAzSo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}